{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor network emulators\n",
    "\n",
    "First, create an environment where the jupyter notebook can run. The next cell does that for you.\n",
    "\n",
    "In general, the places where you should insert your code are marked by the dots `...`.\n",
    "\n",
    "This does not mean that you can complete the task with a one-liner, you might require more lines.\n",
    "The dots are also used because some specific variable names are required to be able to perform the final check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv ./tn_env\n",
    "!source tn_env/bin/activate\n",
    "!pip install numpy, matplotlib\n",
    "!git clone https://baltig.infn.it/quantum_tea_leaves/py_api_quantum_tea_leaves.git\n",
    "!git clone https://baltig.infn.it/quantum_matcha_tea/py_api_quantum_matcha_tea.git\n",
    "!pip install -e ./py_api_quantum_tea_leaves\n",
    "!pip install -e ./py_api_quantum_matcha_tea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "yes =  \"\\033[1;32m\" + u\"\\N{check mark}\" #+ \"\\033[1;30m\"\n",
    "no =  \"\\033[1;31m\" + u\"\\N{ballot x}\" #+ \"\\033[1;30m\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic handling of tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling different shapes\n",
    "\n",
    "<details>\n",
    "  <summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "def my_reshape(vec, shape, idxs):\n",
    "    return vec[ idxs[0] + shape[0]*idxs[1] ]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m✓ Succed!\n"
     ]
    }
   ],
   "source": [
    "vector = np.arange(16, dtype=int)\n",
    "shape = (4, 4)\n",
    "idxs = (2, 2)\n",
    "id\n",
    "\n",
    "def my_reshape(vec, shape, idxs):\n",
    "    \"\"\"\n",
    "    Return the element of the vector `vec` at position `idxs`\n",
    "    as if the vector is a matrix of shape `shape`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec : np.ndarray\n",
    "        Vector of shape (n,)\n",
    "    shape : tuple\n",
    "        New shape of the vector\n",
    "    idxs : tuple\n",
    "        Indexes to access the array value in the\n",
    "        reshaped position\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        value of the array at indexes `idxs`\n",
    "    \"\"\"\n",
    "    return vec[ idxs[0] + shape[0]*idxs[1]]\n",
    "\n",
    "if vector.reshape(shape)[idxs] == my_reshape(vector, shape, idxs):\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Element {vector.reshape(shape)[idxs]} is not the same of your element {my_reshape(vector, shape, idxs)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation\n",
    "\n",
    "Notice that numpy calls `np.transpose` what we call permutation, since it is the multi-dimensional generalization of the matrix transposition.\n",
    "\n",
    "If you have different indexes $x_1, \\dots, x_n$ defined in the ranges $x_1 \\in [0, ..., b_1-1], ..., x_n \\in [0, ..., b_n-1]$\n",
    "then you can write the integer $i$ index that runs over the whole tensor as:\n",
    "$$\n",
    "i = x_n + b_n x_{n-1} + b_n b_{n-1} x_{n-2} + ... + b_n b_{n-1}...b_2 x_1\n",
    "$$\n",
    "\n",
    "<details>\n",
    "  <summary>Hint part 1</summary>\n",
    "  \n",
    "  The ranges are the shapes.\n",
    "\n",
    "  The index at the position 0 is equivalent to $x_n$ of the formula\n",
    "  reported in the comments. The function `np.cumprod` might be useful.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Solution part 1</summary>\n",
    "\n",
    "```python\n",
    "def get_int_idx(shape, idxs):\n",
    "    cumulative_shape = np.cumprod(shape)\n",
    "    idxs = np.array(idxs)\n",
    "    int_idx = idxs[0] + (idxs[1:]*cumulative_shape[:-1]).sum()\n",
    "    return int_idx\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Hint part 2</summary>\n",
    "\n",
    "```python\n",
    "def my_permute(tensor, permutations):\n",
    "    shape = np.array(tensor.shape)\n",
    "    permutations = np.array(permutations)\n",
    "    # Initialize a tensor with the correct shape, which is the permuted shape of the original tensor\n",
    "    new_tensor = np.zeros( ... )\n",
    "    # The permutation is a copy with a different order\n",
    "    for ii in range(shape[0]):\n",
    "        for jj in range(shape[1]):\n",
    "            for kk in range(shape[2]):\n",
    "                new_tensor[...] = tensor[...]\n",
    "\n",
    "    return new_tensor\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Solution part 2</summary>\n",
    "\n",
    "```python\n",
    "def my_permute(tensor, permutations):\n",
    "    shape = np.array(tensor.shape)\n",
    "    permutations = np.array(permutations)\n",
    "    # Initialize a tensor with the correct shape, which is the permuted shape of the original tensor\n",
    "    new_tensor = np.zeros(shape[permutations] )\n",
    "    for ii in range(shape[0]):\n",
    "        for jj in range(shape[1]):\n",
    "            for kk in range(shape[2]):\n",
    "                new_tensor[ii, kk, jj] = tensor[ii, jj, kk]\n",
    "\n",
    "    return new_tensor\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[ 4 12]\n",
      "\u001b[1;32m✓ Succed!\n",
      "\u001b[1;32m✓ Succed!\n"
     ]
    }
   ],
   "source": [
    "# The formula is as follows: if you have x_1, ..., x_n\n",
    "# in the ranges x_1 ∈ {0, ..., b_1-1}, ..., x_n ∈ {0, ..., b_n-1}\n",
    "# then the integer i is defined as:\n",
    "# i = x_n + b_n x_{n-1} + b_n b_{n-1} x_{n-2} + ... + b_n b_{n-1}...b_2 x_1\n",
    "\n",
    "shape = (2, 3, 4)\n",
    "idxs = (1, 0, 0)\n",
    "vector = np.arange(np.prod(shape))\n",
    "\n",
    "def get_int_idx(shape, idxs):\n",
    "    \"\"\"\n",
    "    Return the integer index corresponding to the tensor index `idxs`\n",
    "        for a tensor of shape `shape`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : tuple\n",
    "        Shape of the tensor\n",
    "    idxs : tuple\n",
    "        Tensor indexes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Integer index corresponding to the tensor index `idxs`\n",
    "        for a tensor of shape `shape`\n",
    "    \"\"\"\n",
    "    shape = np.array(shape)\n",
    "    idxs = np.array(idxs)\n",
    "    cumulative_sum = np.cumprod(shape[::-1])\n",
    "    rev_idx = idxs[::-1]\n",
    "    print(rev_idx)\n",
    "    print(cumulative_sum[:-1])\n",
    "    int_idx= rev_idx[0] + (rev_idx[1:]*cumulative_sum[:-1]).sum()\n",
    "    return int_idx\n",
    "\n",
    "if vector.reshape(shape)[idxs] == vector[get_int_idx(shape, idxs)]:\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Element {vector.reshape(shape)[idxs]} is not the same of your element {vector[get_int_idx(shape, idxs)]}\")\n",
    "\n",
    "\n",
    "permutations = (0, 2, 1)\n",
    "tensor = vector.reshape(shape)\n",
    "\n",
    "def my_permute(tensor, permutations):\n",
    "    \"\"\"\n",
    "    Permute the indexes of the tensor `tensor`\n",
    "    using the permutation `permutations`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : np.ndarray\n",
    "        Rank-3 tensor\n",
    "    permutations : tuple\n",
    "        Permutation of the tensor indexes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Permuted tensor\n",
    "    \"\"\"\n",
    "    shape = np.array(tensor.shape)\n",
    "    permutations = np.array(permutations)\n",
    "    new_tensor = np.zeros(shape[permutations])\n",
    "    for ii in range(shape[0]):\n",
    "        for jj in range(shape[1]):\n",
    "            for kk in range(shape[2]):\n",
    "                new_tensor[ii,kk,jj] =tensor[ii, jj, kk] \n",
    "\n",
    "    return new_tensor\n",
    "\n",
    "if np.isclose( tensor.transpose(permutations), my_permute(tensor, permutations) ).all() :\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractions\n",
    "\n",
    "Perform the tensor contraction of the following tensors using matrix-matrix multiplication (you should not use `np.tensordot` at this level.):\n",
    "\n",
    "1. The Index `1` of tensor `tens_1` is contracted with the indexes `(0, 1)` of tensor `tens_2`\n",
    "   <details>\n",
    "   <summary>Hint part 1</summary>\n",
    "   You should merge the indexes of `tens_2` using a reshape\n",
    "   </details>\n",
    "2. The Index `1` of tensor `tens_1` is contracted with the indexes `0` of tensor `tens_2`\n",
    "   <details>\n",
    "   <summary>Hint part 2</summary>\n",
    "   You should merge the indexes of `tens_2` using a reshape\n",
    "   </details>\n",
    "3. The Index `1` of tensor `tens_1` is contracted with the indexes `2` of tensor `tens_2`\n",
    "   <details>\n",
    "   <summary>Hint part 3</summary>\n",
    "   On top of what you did before, you have to transpose something on `tens_2`\n",
    "   </details>\n",
    "4. The Index `(0, 1)` of tensor `tens_1` is contracted with the indexes `(1, 2)` of tensor `tens_2`\n",
    "   <details>\n",
    "   <summary>Hint part 4</summary>\n",
    "   Transpose `tens_1` and `tens_2`, reshape them and you are there!\n",
    "   </details>\n",
    "\n",
    "Recall that in python the symbol `@` is a matrix-matrix multiplication. Thus, `np.matmul(A, B) = A @ B`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m✓ Succed!\n",
      "\u001b[1;32m✓ Succed!\n",
      "\u001b[1;32m✓ Succed!\n",
      "\u001b[1;32m✓ Succed!\n"
     ]
    }
   ],
   "source": [
    "def get_tens(shape):\n",
    "    return np.arange(np.prod(shape)).reshape(shape)\n",
    "\n",
    "\n",
    "# ----------------------------- 1 -----------------------------\n",
    "shape_1, shape_2 = (4, 6), (2, 3, 8)\n",
    "tens_1, tens_2 = get_tens(shape_1), get_tens(shape_2)\n",
    "\n",
    "result = tens_1@ np.reshape(tens_2, [2*3, 8])\n",
    "\n",
    "if np.isclose( np.tensordot(tens_1, tens_2.reshape(6, 8), ([1], [0])), result ).all() :\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")\n",
    "\n",
    "# ----------------------------- 2 -----------------------------\n",
    "shape_1, shape_2 = (4, 2), (2, 3, 8)\n",
    "tens_1, tens_2 = get_tens(shape_1), get_tens(shape_2)\n",
    "\n",
    "result = np.tensordot(tens_1, tens_2, ([1], [0]))\n",
    "\n",
    "if np.isclose( np.tensordot(tens_1, tens_2, ([1], [0])), result ).all() :\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")\n",
    "\n",
    "# ----------------------------- 3 -----------------------------\n",
    "shape_1, shape_2 = (4, 6), (2, 3, 6)\n",
    "tens_1, tens_2 = get_tens(shape_1), get_tens(shape_2)\n",
    "\n",
    "result = np.tensordot(tens_1, tens_2, ([1], [2]))\n",
    "\n",
    "if np.isclose( np.tensordot(tens_1, tens_2, ([1], [2])), result ).all() :\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")\n",
    "\n",
    "# ----------------------------- 4 -----------------------------\n",
    "shape_1, shape_2 = (4, 6, 10), (2, 4, 6)\n",
    "tens_1, tens_2 = get_tens(shape_1), get_tens(shape_2)\n",
    "\n",
    "result = np.tensordot(tens_1, tens_2 , ([0,1], [1,2]))\n",
    "\n",
    "if np.isclose( np.tensordot(tens_1, tens_2, ([0, 1], [1, 2])), result ).all() :\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular value decomposition\n",
    "\n",
    "Starting from the order 4 tensor `tens` apply an SVD splitting legs (0, 1) and (2, 3).\n",
    "\n",
    "1. Check that the singular values are `[s_1, s_2, 0, 0]`\n",
    "2. Contract the singular values to the `V_mat` matrix (right matrix);\n",
    "3. reshape `U_mat` into a (1, 2, n) tensor and `V_mat` in a (n, 2, 1) tensor;\n",
    "4. Contract the tensor network by first contracting `U_tens` and then `V_tens`;\n",
    "5. Can you obtain the same result using only `V_tens`? And only `U_tens`? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.70710678 0.        ]\n",
      "   [0.         0.        ]]\n",
      "\n",
      "  [[0.         0.        ]\n",
      "   [0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.        ]\n",
      "   [0.         0.        ]]\n",
      "\n",
      "  [[0.         0.        ]\n",
      "   [0.         0.70710678]]]]\n",
      "[[0.70710678 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.70710678]]\n",
      "[[0.70710678 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.70710678]]\n",
      "[[[1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1. 0. 1. 0. 0.]]]\n",
      "[[[1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]]]\n",
      "\u001b[1;31m✗ Failed! \n"
     ]
    }
   ],
   "source": [
    "tens = np.zeros(2**4)\n",
    "tens[[0, -1]] = 1/np.sqrt(2)\n",
    "tens = tens.reshape([2]*4)\n",
    "print(tens)\n",
    "tens = tens.reshape([4,4])\n",
    "print(tens)\n",
    "\n",
    "tens = np.reshape(tens, [4,4])\n",
    "print(tens)\n",
    "\n",
    "U_mat, singvals, V_mat = np.linalg.svd(tens)\n",
    "V_mat = np.tensordot(singvals,V_mat, ([0],[0]))\n",
    "np.shape(U_mat)\n",
    "U_tens = U_mat.reshape((1,2,-1))\n",
    "V_tens = U_mat.reshape((-1,2,1))\n",
    "\n",
    "print(U_tens)\n",
    "print(V_tens)\n",
    "\n",
    "result_contraction = 0\n",
    "\n",
    "if np.isclose( result_contraction, 1 ):\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image compression with SVD\n",
    "\n",
    "Apply the SVD to the image, and before contracting the singular value to `V_mat` cut a part of them.\n",
    "\n",
    "How many singvals can you cut while still enjoying the Shiba blinking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im_frame = Image.open('shibapng.png').convert('1')\n",
    "image = np.array(im_frame.getdata())\n",
    "x = int(np.sqrt(len(image)))\n",
    "image = image.reshape(-1, 820)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_mat, singvals, V_mat = np.linalg.svd(image)\n",
    "\n",
    "U_mat = ...\n",
    "singvals = ...\n",
    "V_mat = np.tensordot(...)\n",
    "\n",
    "image = ...\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum emulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your own MPS\n",
    "\n",
    "Write the MPS state of the following quantum state:\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\frac{1}{\\sqrt 2}\\left(|000\\rangle + |111\\rangle\\right)\n",
    "$$\n",
    "\n",
    "1. Apply the SVD to the tensor of leg (0) w.r.t. legs 1,2\n",
    "2. Write `U_tens` as a (1, 2, n) tensor\n",
    "3. Apply the SVD to `V_mat` of legs (0, 1) w.r.t. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_z = np.array([[1, 0], [0, -1]])\n",
    "sigma_x = np.array([[0, 1], [1, 0]])\n",
    "cx = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtealeaves.emulator import MPS\n",
    "from qtealeaves.convergence_parameters import TNConvergenceParameters\n",
    "\n",
    "num_qubs = 3\n",
    "tens = np.zeros(2**num_qubs)\n",
    "tens[[0, -1]] = 1/np.sqrt(2)\n",
    "mps_list = []\n",
    "\n",
    "\n",
    "# Divide first qubit from the rest of the state\n",
    "U_mat, singvals, V_mat = np.linalg.svd(...)\n",
    "V_mat = np.tensordot(...)\n",
    "\n",
    "U_tens = ...\n",
    "V_tens = ...\n",
    "mps_list.append(U_tens)\n",
    "\n",
    "# Divide first qubit from the rest of the state\n",
    "U_mat, singvals, V_mat = np.linalg.svd(V_tens, ...)\n",
    "V_mat = np.tensordot(...)\n",
    "\n",
    "U_tens = ...\n",
    "mps_list.append(U_tens)\n",
    "\n",
    "V_tens = ...\n",
    "mps_list.append(V_tens)\n",
    "\n",
    "\n",
    "mps_state = MPS.from_statevector(tens.reshape(-1))\n",
    "\n",
    "if [np.isclose( tens1, tens2 ).all() for tens1, tens2 in zip(mps_list, mps_state)].all():\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of gates to the MPS\n",
    "\n",
    "Starting from the state $|00...0\\rangle$ go to the GHZ state applying single and two-qubits gates.\n",
    "Use the native function to shift the isometry center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 10\n",
    "conv_params = TNConvergenceParameters(max_bond_dimension=128)\n",
    "mps_state = MPS(num_qubits, conv_params)\n",
    "\n",
    "ghz = np.zeros(2**num_qubs)\n",
    "ghz[[0, -1]] = 1/np.sqrt(2)\n",
    "\n",
    "\n",
    "site_0 = mps_state[0]\n",
    "# Apply the single qubit gate\n",
    "site_0_new = ...\n",
    "\n",
    "mps_state._tensors[0] = site_0_new\n",
    "\n",
    "# Apply the two-qubit gates\n",
    "for ii in range(num_qubits-1):\n",
    "    # Move the isometry center. It is actually moved automatically\n",
    "    # due to how we apply the two-qubit gates, but it would be necessary\n",
    "    # if the gates were not always between i,i+1\n",
    "    mps_state.site_canonize(ii, True)\n",
    "\n",
    "    site_ii = mps_state[ii]\n",
    "    site_ii_1 = mps_state[ii+1]\n",
    "\n",
    "    # Contract the two qubits\n",
    "    two_qubits = ...\n",
    "    # Contract the resulting tensor with the gate\n",
    "    tensors_after_application = ...\n",
    "    # Split the gate\n",
    "    U_mat, singvals, V_mat = np.linalg.svd(...)\n",
    "\n",
    "    # Truncate the singular values, keep only the singvals > 0\n",
    "    U_mat = ...\n",
    "    singvals = ...\n",
    "    V_mat = np.tensordot(...)\n",
    "\n",
    "    # Reshape in the correct order\n",
    "    U_tens = ...\n",
    "    V_tens = ...\n",
    "\n",
    "    mps_state._tensors[ii] = U_tens\n",
    "    mps_state._tensors[ii+1] = V_tens\n",
    "    mps_state._singvals[ii+1] = singvals\n",
    "\n",
    "if np.isclose(np.vdot(mps_state.to_statevector(), ghz), 1):\n",
    "    print( yes + \" Succed!\")\n",
    "else:\n",
    "    print(  no + f\" Failed! \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Quantum Matcha TEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from qiskit import QuantumCircuit\n",
    "import qtealeaves.observables as obs\n",
    "from qmatchatea import QCConvergenceParameters, run_simulation, QCBackend\n",
    "from qmatchatea.qk_utils import QFT_qiskit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the quantum circuit you want to emulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 20\n",
    "\n",
    "qc = QuantumCircuit(num_qubits)\n",
    "\n",
    "state = \"product\"\n",
    "\n",
    "if state == \"product\":\n",
    "    # Add your code here to prepare your choice quantum state. For example apply a QFT to product state\n",
    "    for ii in range(num_qubits):\n",
    "        qc.h(ii)\n",
    "elif state == \"ghz\":\n",
    "    # Add your code here to prepare your choice quantum state. For example apply a QFT to ghz state\n",
    "    qc.h(0)\n",
    "    for ii in range(num_qubits-1):\n",
    "        qc.cx(ii, ii+1)\n",
    "elif state == \"random\":\n",
    "    # Add your code here for the random state. Is it as fast as the other two?\n",
    "    ...\n",
    "    # try other initialization if you want\n",
    "\n",
    "\n",
    "# Appy a QFT\n",
    "QFT_qiskit(qc, num_qubits)\n",
    "\n",
    "print(\"Circuit defined!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to choose between different approaches for running the simulation:\n",
    "\n",
    "- The backend can be either python \"PY\" or fortran \"FR\".\n",
    "- The machine precision can be either double complex \"Z\" or single complex \"C\".\n",
    "- The device of the simulation can be either \"cpu\" or \"gpu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = QCBackend(\n",
    "    backend=\"PY\", precision=\"Z\", device=\"cpu\", num_procs=1, mpi_approach=\"SR\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the convergence parameters, in particular the maximum bond dimension.\n",
    "The maximum bond dimension controls how much entanglement we can encode in\n",
    "the system while still obtaining trustful results.\n",
    "The maximum bond dimension reachable for a given number of qubits :math:`n`\n",
    "is $\\chi=2^{\\lfloor\\frac{n}{2}\\rfloor}$. As you see, if we want to\n",
    "encode *any* state we still have an exponential scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_params = QCConvergenceParameters(max_bond_dimension=1024, singval_mode=\"C\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to define the observables for a quantum matcha tea simulation using the observables available in qtealeaves.\n",
    "You can finde all the available at the [qtealeaves observables documentation](https://quantum_tea_leaves.baltig-pages.infn.it/py_api_quantum_tea_leaves/chapters/measurements.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container of all the observables\n",
    "observables = obs.TNObservables()\n",
    "\n",
    "# Local observables\n",
    "observables += obs.TNObsLocal(\"sigma_z\", \"Z\")\n",
    "\n",
    "# Entanglement entropy\n",
    "observables += obs.TNObsBondEntropy()\n",
    "\n",
    "# Projective measurements\n",
    "observables += obs.TNObsProjective(1024)\n",
    "\n",
    "# Probability measurement\n",
    "observables += obs.TNObsProbabilities()\n",
    "\n",
    "# Tensor product observable, such as the parity of the whole state\n",
    "observables += obs.TNObsTensorProduct(\"parity\", [\"Z\" for _ in range(num_qubits)], [[ii] for ii in range(num_qubits)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulation and obtain the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_simulation(\n",
    "    qc,\n",
    "    convergence_parameters = conv_params,\n",
    "    observables=observables,\n",
    "    backend=backend\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the results to extract the informations you are interested about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in results.observables.items():\n",
    "    print(\"-\"*50, key, \"-\"*50)\n",
    "    print(val)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there was any truncation during the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The fidelity of the simulation is {results.fidelity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
